<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.8.0" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.8.0" type="image/png" sizes="32x32"><meta name="description" content="BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View        本文链接: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2112.11790 代码仓库: https:&#x2F;&#x2F;github.com&#x2F;HuangJunJie2017&#x2F;BEVDet">
<meta property="og:type" content="article">
<meta property="og:title" content="【看论文】BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View">
<meta property="og:url" content="http://hipposox.github.io/2022/10/02/BEVDet/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View        本文链接: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2112.11790 代码仓库: https:&#x2F;&#x2F;github.com&#x2F;HuangJunJie2017&#x2F;BEVDet">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://hipposox.github.io/image/BEVDet/BEVDet_02.png">
<meta property="og:image" content="http://hipposox.github.io/image/BEVDet/BEVDet_01.png">
<meta property="og:image" content="http://hipposox.github.io/image/BEVDet/BEVDet_03.png">
<meta property="article:published_time" content="2022-10-02T11:59:56.000Z">
<meta property="article:modified_time" content="2023-01-10T10:11:11.497Z">
<meta property="article:author" content="HippoSoX">
<meta property="article:tag" content="看论文">
<meta property="article:tag" content="BEVDet">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://hipposox.github.io/image/BEVDet/BEVDet_02.png"><title>【看论文】BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View | Hexo</title><link ref="canonical" href="http://hipposox.github.io/2022/10/02/BEVDet/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.8.0"><link rel="stylesheet" href="css/custom.css"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"dark","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: true,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.2"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">erocool</div><div class="header-banner-info__subtitle">You know what</div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">【看论文】BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2022-10-02</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-01-10</span></span></div></header><div class="post-body">
        <h1 id="bevdet-high-performance-multi-camera-3d-object-detection-in-bird-eye-view"   >
          <a href="#bevdet-high-performance-multi-camera-3d-object-detection-in-bird-eye-view" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#bevdet-high-performance-multi-camera-3d-object-detection-in-bird-eye-view"></a> BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View</h1>
      
<p>本文链接: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.11790" >https://arxiv.org/abs/2112.11790</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>代码仓库: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/HuangJunJie2017/BEVDet" >https://github.com/HuangJunJie2017/BEVDet</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h2 id="abstract-摘要"   >
          <a href="#abstract-摘要" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#abstract-摘要"></a> Abstract 摘要</h2>
      
<p>自主驾驶能够感知周围环境进行决策，这是视觉感知中最复杂的场景之一。范式创新在解决2D对象检测任务方面的成功激励我们寻求一种优雅、可行和可扩展的范式，从根本上推动这一领域的性能边界。为此，我们在本文中贡献了<strong>BEVDet范式</strong>。BEVDet在<strong>鸟瞰图（BEV）<strong>中执行</strong>三维目标检测</strong>，其中定义了大多数目标值，可以方便地执行路线规划。我们仅重用现有模块来构建其框架，但通过构建专用数据增强策略和升级非最大抑制策略来大幅提高其性能。在实验中，BEVDet在准确性和时间效率之间提供了一个极好的折衷方案。作为快速版本，BEVDet Tiny在nuScenes值集上的mAP得分为31.2%，NDS得分为39.2%。它与FCOS3D相当，但只需要215.3个GFLOP的11%计算预算，以15.6FPS的速度运行快9.2倍。另一个被称为BEVDet Base的高精度版本得分为39.3%mAP和47.2%NDS，大大超过所有公布的结果。凭借相当的推理速度，它以+9.8%mAP和+10.0%NDS的大幅度优势超过了FCOS3D。源代码公开供进一步研究。</p>
<span id="more"></span>

        <h2 id="introduction-介绍"   >
          <a href="#introduction-介绍" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#introduction-介绍"></a> Introduction 介绍</h2>
      
<p>在过去的几年里，2D视觉感知得到了快速发展，并出现了一些杰出的范例，如Mask R-CNN，它具有高性能、可扩展性和多任务兼容。然而，对于需要<strong>精确性</strong>和<strong>时间效率</strong>的基于视觉的自动驾驶场景，诸如<strong>3D物体检测</strong>和**地图恢复（即鸟瞰视图（BEV）语义分割）**等主要任务仍由最新基准中的不同范式执行。例如，在nuScenes基准测试中，基于图像视图的方法（如FCOS3D和PGD）在多摄像机3D对象检测跟踪中具有领先性能，而BEV语义分割跟踪主要由基于BEV的方法（例如PON、Lift Splat Shoot和VPN）控制。在自动驾驶中，哪种视野空间更适合感知，我们能否在统一的框架内处理这些任务？针对这些问题，本文提出了BEVDet。利用BEVDet，我们探索了在BEV中检测3D对象的优势，与最新的基于图像视图的方法相比，它具有更高的性能，并且与BEV语义分割具有一致的范式。通过这种方式，我们可以进一步验证多任务学习的可行性，这对于高效推理具有重要意义。</p>
<p>如图1所示，提出的<strong>BEVDet</strong>与最新的BEV语义分割算法具有类似的框架。它是<strong>模块化设计</strong>的，具有用于<strong>在图像视图中编码特征</strong>的<strong>图像视图编码器</strong>、用于<strong>将特征从图像视图转换为BEV</strong>的<strong>视图转换器</strong>、用于<strong>在BEV透视图中进一步编码特征</strong>的<strong>BEV编码器</strong>，以及用于<strong>在BEW空间中执行3D物体检测</strong>的<strong>特定任务头</strong>。得益于这种模块化设计，我们可以重用大量在其他领域已被证明有效的现有作品，并且还需要很长一段时间才能升级这种特定于3D物体检测任务的范例。</p>
<p>虽然BEVDet的框架构造简单，但构建其健壮的性能并不容易。在验证BEVDet的可行性时，为了合理的性能，将BEVDet数据处理策略和参数编号设置为接近基于图像视图的三维物体检测器，如FCOS3D和PGD。出乎意料的是，在培训过程中发现了一个严重的过拟合问题。一些线索表明，问题在于BEVDet在BEV空间中的安装容量过大。首先，过度拟合鼓励我们在图像视图空间中应用复杂的数据增强策略，如Lift Splat Shoot，以获得规则化效果。然而，只有当BEV编码器不存在时，此修改才会产生积极影响。否则，它甚至会降低性能。另一方面，图像视图编码器的批量大小是子序列模块的N倍（即，nuScenes中的6个摄像头的数量）。训练数据不足也是BEV空间学习过度拟合的部分原因。此外，我们观察到视图转换器以像素方式连接图像视图空间和BEV空间，从数据增强的角度将它们解耦。这使得图像视图中的数据增强对子序列模块（即BEV编码器和3D物体检测头）没有正则化影响。因此，作为补充，在BEV空间中执行额外的数据增强操作，如翻转、缩放和旋转，以增强模型在这些方面的鲁棒性。这可以很好地防止BEVDet过拟合。</p>
<p>此外，我们对经典的非最大值抑制（NMS）策略进行了升级，以提高其在三维目标检测场景中的适应性。通过删除顺序执行的运算符，推理过程进一步加快。通过这些修改，BEVDet在现有范例中的准确性和推理延迟之间提供了一个出色的折衷方案。在nuScenes val集合上，高速版本BEVDet Tiny的图像大小为704×256，达到了极高的精度（即31.2%mAP和39.2%NDS），仅为竞争对手的1/8（即29.5%mAP和37.2%NDS，FCOS3D中的1600×900图像大小）。缩小图像大小将减少89%的计算预算，并提供9.2倍的显著加速（即，BEVDet具有215.3 GFLOP和15.6 FPS，而FCOS3D具有2008.2 GFLOPs和1.7 FPS）。通过构建另一个名为BEVDet Base的高精度配置，我们报告了39.3%mAP和47.2%NDS的新记录。此外，与现有范式相比，在BEV空间中明确编码特征使BEVDet能够感知目标的平移、规模、方向和速度。在消融研究中可以发现BEVDet的更多特征。</p>

        <h2 id="network-structure-网络结构"   >
          <a href="#network-structure-网络结构" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#network-structure-网络结构"></a> Network Structure 网络结构</h2>
      
<p>如图1所示，具有模块化设计的BEVDet由四种模块组成：<strong>图像视图编码器</strong>、<strong>视图转换器</strong>、<strong>BEV编码器</strong>和<strong>特定于任务的头部</strong>。我们通过构建几个具有不同结构的衍生物，如表1所示。</p>
<p>表1.BEVDet的组件。”-number”表示此模块中的通道数。Lift-Splat-Shoot-64-0.4×0.4表示中建议的视图变换器。输出功能的通道数为64，分辨率为0.4米</p>

        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="/image/BEVDet/BEVDet_02.png"  loading="lazy"/>
      

        <img  alt="BEVDet网络结构图"  class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="/image/BEVDet/BEVDet_01.png"  loading="lazy"/>
      
图1.拟议BEVDet范式的框架。
<p>BEVDet采用模块化设计，由四个模块组成：<strong>图像视图编码器</strong>首先用于<strong>图像特征提取</strong>，包括<strong>主干</strong>和<strong>颈部</strong>。<strong>视图转换器将特征从图像视图转换为BEV</strong>。<strong>BEV编码器</strong>进一步<strong>编码BEV特性</strong>。最后，<strong>基于BVE特征</strong>构建一个<strong>特定于任务的头部</strong>，并<strong>预测3D对象的目标值</strong>。我们以BEVDet Tiny为例来说明不同模块的通道。</p>
<p><strong>图像视图</strong> 图像视图编码器将输入图像编码为高级特征。为了利用多分辨率特征的威力，图像视图编码器包括用于高级别特征提取的主干和用于多分辨率特征融合的瓶颈。默认情况下，我们使用经典的ResNet和最新的基于注意力的SwinTransformer作为原型研究的基础。替代品包括DenseNet、HRNet等。关于颈部模块，我们使用经典的FPN和中提出的颈部结构，以下称为FPN-LSS。FPN-LSS只需将输入分辨率为1/32的特征提升到1/16的输入分辨率，并将其与主干生成的特征串联起来。更复杂的颈部模块尚未开发，如PAFPN、NAS-FPN等。</p>
<p><strong>视图转换器</strong> 视图转换器将特征从图像视图转换为BEV。我们应用中提出的视图转换器来构建BEVDet原型。所采用的视图变换器以图像视图特征为输入，通过分类方式密集预测深度。然后，在渲染预定义的点云时，使用分类分数和导出的图像视图特征。最后，可以通过沿垂直方向（即图1所示的Z坐标轴）应用池操作来生成BEV特征。实际上，我们将深度预测的默认范围扩展到米，间隔为1.25×r，其中r表示输出特征的分辨率。</p>
<p><strong>BEV编码器</strong> BEV编码器进一步对BEV空间中的特征进行编码。虽然其结构类似于具有主干和颈部的图像视图编码器，但它可以以高精度感知一些关键线索，如在BEV空间中定义的比例、方向和速度。我们遵循，利用ResNet和经典残差块构造主干，并通过应用FPN-LSS将不同分辨率的特征结合起来。</p>
<p><strong>头部</strong> 特定于任务的头部是基于BEV功能构建的。通常，自动驾驶仪中的三维物体检测是针对行人、车辆、障碍物等移动物体的位置、比例、方向和速度进行的。我们在不做任何修改的情况下，直接采用CenterPoint第一阶段的三维物体探测头进行原型验证，并与基于LiDAR的PointPillar和VoxelNet管道进行公平比较。尚未应用CenterPoint的第二个优化阶段。</p>

        <h2 id="the-customized-data-augmentation-strategy-定制数据增强策略"   >
          <a href="#the-customized-data-augmentation-strategy-定制数据增强策略" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#the-customized-data-augmentation-strategy-定制数据增强策略"></a> The Customized Data Augmentation Strategy 定制数据增强策略</h2>
      
<p><strong>孤立视图空间</strong> 视图转换器以像素方式将特征从图像视图转换为BEV。具体地说，给定图像平面<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>i</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi></mrow></msub><mo>=</mo><mo stretchy="false">[</mo><mi>x</mi><mi>i</mi><mtext>，</mtext><mi>y</mi><mi>i</mi><mtext>，</mtext><mn>1</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">P_{image}=[xi，yi，1]^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">x</span><span class="mord mathnormal">i</span><span class="mord cjk_fallback">，</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">i</span><span class="mord cjk_fallback">，</span><span class="mord">1</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>中具有特定深度d的像素，三维空间中的对应坐标为：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>P</mi><mrow><mi>c</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>r</mi><mi>a</mi></mrow></msub><mo>=</mo><msup><mi>I</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><msub><mi>P</mi><mrow><mi>i</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi></mrow></msub><mo>∗</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P_{camera}=I^{-1}(P_{image}*d)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.150216em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中I是3×3相机内参矩阵。的常见数据增强策略例如翻转、裁剪和旋转等操作可以表示为3×3变换矩阵A。当对输入图像（即<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>i</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi></mrow></msub><mo>=</mo><msub><mi>A</mi><msub><mi>P</mi><mrow><mi>i</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi></mrow></msub></msub></mrow><annotation encoding="application/x-tex">P_{image}=A_{P_{image}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.03065em;vertical-align:-0.34731999999999996em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833100000000004em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.13889em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34731999999999996em;"><span></span></span></span></span></span></span></span></span></span>）应用数据增强策略时，逆变换<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">A^{-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>应该应用于视图转换，以保持BEV空间中特征和目标之间的空间一致性：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>P</mi><mrow><mi>c</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>r</mi><mi>a</mi></mrow></msub><mo>=</mo><msup><mi>I</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><msubsup><mi>A</mi><msub><mi>P</mi><mrow><mi>i</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi></mrow></msub><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mo>∗</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>P</mi><mrow><mi>c</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>r</mi><mi>a</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_{camera}=I^{-1}(A^{-1}_{P_{image}}*d)=P_{camera}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.34509em;vertical-align:-0.48098199999999997em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.416338em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.13889em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.48098199999999997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>根据公式2，应用于图像视图空间的增强策略不会改变BEV空间中特征的空间分布。这使得在图像视图空间中执行复杂的数据增强策略对于BEVDet是可行的。</p>
<p><strong>BEV空间学习与数据增强</strong> 关于BEV空间中的学习，由于每个样本包含多个相机图像（例如nuScenses基准中的每个样本包含6个图像），因此数据的数量小于图像视图空间中的数据数量。因此，在BEV空间中学习容易陷入过度拟合。由于视图变换器在增强透视图中隔离了两个视图空间，因此我们构造了另一种增强策略，专门针对正则化对BEV空间学习的影响。根据最新的基于激光雷达的方法，在二维空间中采用了常见的数据增强操作，包括翻转、缩放和旋转。在实践中，对视图变换器的输出特征和三维目标检测目标进行操作，以保持它们的空间一致性。值得注意的是，这种数据增强策略是建立在视图转换器可以将图像视图编码器与后续模块解耦的前提下的。这是BEVDet的一个特殊特性，在其他方法中可能无效。</p>

        <h2 id="scale-nms-缩放nms"   >
          <a href="#scale-nms-缩放nms" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#scale-nms-缩放nms"></a> Scale-NMS 缩放NMS</h2>
      

        <img  alt ="数据增强"  class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="/image/BEVDet/BEVDet_03.png"  loading="lazy"/>
      
<p>BEV空间中不同类别的空间分布与图像视图空间中的分布有很大的不同。在图像视图空间中，由于相机的透视成像机制，所有类别共享相似的空间分布。因此，具有固定阈值的经典非最大值抑制（NMS）策略可以很好地调整所有类别的预测结果，以符合先验值（例如，在2D对象检测中，两个实例之间的边界框相交于并（IOU）指示器始终低于特定阈值0.5）。然而，在BEV空间中是不同的。在BEV空间中，各个类的占用面积本质上是不同的，实例之间的重叠应该接近于零。因此，预测结果之间的借据分布因类别而异。例如，如图2所示，行人和交通锥等物体在地平面上占据一小块区域，该区域始终小于算法的输出分辨率（例如，在CenterPoint中为0.8米）。常见的目标检测范式冗余地生成预测。每个对象占用的小面积可能会使冗余结果与真正的正结果不相交。这使依赖借据访问真阳性和假阳性之间的空间关系的经典NMS失效。</p>
<p>为了克服上述问题，我们在本文中提出了Scale NMS。Scale NMS在执行经典NMS算法之前，根据对象的类别缩放每个对象的大小。通过这种方式，调整真正结果和冗余结果之间的IOU分布，以匹配经典NMS。如图2第二行所示，在预测小对象时，Scale NMS通过缩放对象大小来建立结果之间的空间关系，这使得经典NMS能够根据IOU指标来删除冗余对象。在实践中，我们将Scale NMS应用于除屏障外的所有类别，因为其大小各不相同。比例因子是特定于类别的。它们是通过对验证集进行超参数搜索生成的。</p>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="http://hipposox.github.io">HippoSoX</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="http://hipposox.github.io/2022/10/02/BEVDet/">http://hipposox.github.io/2022/10/02/BEVDet/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="http://hipposox.github.io/tags/%E7%9C%8B%E8%AE%BA%E6%96%87/">看论文</a></span><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="http://hipposox.github.io/tags/BEVDet/">BEVDet</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2022/10/03/BEVFormer/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">【看论文】BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers</span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#bevdet-high-performance-multi-camera-3d-object-detection-in-bird-eye-view"><span class="toc-number">1.</span> <span class="toc-text">
           BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#abstract-%E6%91%98%E8%A6%81"><span class="toc-number">1.1.</span> <span class="toc-text">
           Abstract 摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction-%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.</span> <span class="toc-text">
           Introduction 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#network-structure-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">1.3.</span> <span class="toc-text">
           Network Structure 网络结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#the-customized-data-augmentation-strategy-%E5%AE%9A%E5%88%B6%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E7%AD%96%E7%95%A5"><span class="toc-number">1.4.</span> <span class="toc-text">
           The Customized Data Augmentation Strategy 定制数据增强策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scale-nms-%E7%BC%A9%E6%94%BEnms"><span class="toc-number">1.5.</span> <span class="toc-text">
           Scale-NMS 缩放NMS</span></a></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">motto</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">9</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">0</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">9</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1449790718&auto=1&height=66"></iframe></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2023</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>HippoSoX</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v5.4.2</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.8.0</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lazyload@2.0.0-rc.2/lazyload.min.js"></script><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" rel="stylesheet" type="text/css"><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.css" rel="stylesheet" type="text/css"><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.min.js"></script><script src="/js/utils.js?v=2.8.0"></script><script src="/js/stun-boot.js?v=2.8.0"></script><script src="/js/scroll.js?v=2.8.0"></script><script src="/js/header.js?v=2.8.0"></script><script src="/js/sidebar.js?v=2.8.0"></script></body></html>